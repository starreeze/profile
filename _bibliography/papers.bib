---
---

@inproceedings{xing2023drin,
  abbr        = {ACMMM},
  title       = {DRIN: Dynamic Relation Interactive Network for Multimodal Entity Linking},
  author      = {Xing*, Shangyu and Zhao*, Fei and Wu, Zhen and Li, Chunhui and Zhang, Jianbing and Dai, Xinyu},
  booktitle   = {Proceedings of the 31st ACM International Conference on Multimedia},
  pages       = {3599--3608},
  year        = {2023},
  bibtex_show = {true},
  arxiv       = {2310.05589},
  code        = {https://github.com/starreeze/drin},
  selected    = {true}
}

@inproceedings{zhao2022learning,
  abbr        = {ACMMM},
  title       = {Learning from different text-image pairs: a relation-enhanced graph convolutional network for multimodal NER},
  author      = {Zhao, Fei and Li, Chunhui and Wu, Zhen and Xing, Shangyu and Dai, Xinyu},
  booktitle   = {Proceedings of the 30th ACM international conference on multimedia},
  pages       = {3983--3992},
  year        = {2022},
  url         = {https://dl.acm.org/doi/10.1145/3503161.3548228},
  code        = {https://github.com/1429904852/R-GCN},
  bibtex_show = {true}
}

@article{xing2024efuf,
  abbr        = {EMNLP},
  title       = {EFUF: Efficient Fine-grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models},
  author      = {Xing, Shangyu and Zhao, Fei and Wu, Zhen and An, Tuo and Chen, Weihao and Li, Chunhui and Zhang, Jianbing and Dai, Xinyu},
  journal     = {EMNLP 2024},
  year        = {2024},
  bibtex_show = {true},
  arxiv       = {2402.09801},
  code        = {https://github.com/starreeze/efuf},
  selected    = {true}
}

@article{zhao2024aligngpt,
  abbr        = {preprint},
  title       = {AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability},
  author      = {Zhao, Fei and Pang, Taotian and Li, Chunhui and Wu, Zhen and Guo, Junjie and Xing, Shangyu and Dai, Xinyu},
  journal     = {submitted to ICCV 2025},
  year        = {2024},
  bibtex_show = {true},
  arxiv       = {2405.14129},
  code        = {https://github.com/AlignGPT-VL/AlignGPT}
}

@inproceedings{zhou2024anyprefer,
  abbr        = {ICLR},
  title       = {AnyPrefer: An Automatic Framework for Preference Data Synthesis},
  author      = {Zhou, Yiyang and Wang, Zhaoyang and Wang, Tianle and Xing, Shangyu and Xia, Peng and Li, Bo and Zheng, Kaiyuan and Zhang, Zijian and Chen, Zhaorun and Zheng, Wenhao and Xuchao Zhang and Chetan Bansal and Weitong Zhang and Ying Wei and Mohit Bansal and Huaxiu Yao},
  booktitle   = {International Conference on Learning Representations},
  year        = {2025},
  bibtex_show = {true},
  selected    = {true}
}

@article{xing2024gepbenchevaluatingfundamentalgeometric,
  abbr        = {preprint},
  title       = {GePBench: Evaluating Fundamental Geometric Perception for Multimodal Large Language Models},
  author      = {Shangyu Xing and Changhao Xiang and Yuteng Han and Yifan Yue and Zhen Wu and Xinyu Liu and Zhangtai Wu and Fei Zhao and Xinyu Dai},
  year        = {2025},
  arxiv       = {2412.21036},
  journal     = {submitted to ACL 2025},
  slides      = {gepbench_slides.pdf},
  bibtex_show = {true},
  selected    = {true}
}

@article{bert-comp,
  abbr    = {preprint},
  title   = {Maximizing the Effectiveness of Larger BERT Models for Compression},
  author  = {Wenshu Fan and Su Lu and Shangyu Xing and Xinchun Li and Dechuan Zhan},
  year    = {2025},
  journal = {submitted to ACL 2025}
}